
# ğŸ§  IntelliSense AI â€“ Full Stack Setup Guide

IntelliSense AI is an agentic RAG-powered intelligence system that enables advanced document understanding, session management, and real-time chat interactions.

---

## ğŸ—ï¸ Project Architecture

- **Backend:** FastAPI (Python) powered by `uv` & `Agno`
- **Frontend:** React (TypeScript) with Tailwind CSS
- **Database/Cache:** Redis
- **Vector DB:** Pinecone
- **LLM/Embeddings:** Groq, Google Generative AI (Gemini), OpenAI

---

## ğŸš€ Quick Start

### 1. **Prerequisites**
Ensure you have the following installed:
- [Python 3.10+](https://www.python.org/)
- [Node.js & npm](https://nodejs.org/)
- [Docker](https://www.docker.com/)
- [uv](https://github.com/astral-sh/uv) (Highly recommended for Python dependency management)

### 2. **Clone the Repository**
```bash
git clone https://github.com/chandankumar123456/intellisense-ai.git
cd intellisense-ai
```

---

## ğŸ› ï¸ Infrastructure Setup

### **Redis (Docker)**
The project requires a Redis instance for session management and caching. Run the following command to start a Redis container:

```bash
docker run -d --name redis-client -p 6379:6379 redis
```

---

## ğŸ Backend Configuration

### **1. Install Dependencies**
We use `uv` for lightning-fast dependency management.
```bash
uv sync
```

### **2. Environment Variables**
Create a `.env` file in the root directory and add the following:
```env
# API Keys
GROQ_API_KEY="your_groq_api_key"
GOOGLE_API_KEY="your_google_api_key"
PINECONE_API_KEY="your_pinecone_api_key"

# Redis Configuration
REDIS_HOST="localhost"
REDIS_PORT=6379

# LangSmith (Optional but recommended)
LANGSMITH_TRACING="true"
LANGSMITH_API_KEY="your_langsmith_api_key"
```

### **3. Run the Backend Server**
```bash
uv run uvicorn app.main:app --reload
```
The backend will be available at: `http://localhost:8000`

---

## âš›ï¸ Frontend Configuration

### **1. Install Dependencies**
Navigate to the frontend directory:
```bash
cd notebook-lm-frontend
npm install
```

### **2. Run the Development Server**
```bash
npm start
```
The frontend will be available at: `http://localhost:3000`

---

## ğŸ“‚ Project Structure

```text
IntelliSense-AI/
â”œâ”€â”€ app/                    # Backend Source Code
â”‚   â”œâ”€â”€ api/                # API Routes (Chat, Auth, Ingestion)
â”‚   â”œâ”€â”€ core/               # Shared logic (Redis Client, Logging)
â”‚   â””â”€â”€ main.py             # FastAPI Entry Point
â”œâ”€â”€ notebook-lm-frontend/   # Frontend Source Code
â”‚   â”œâ”€â”€ src/                # React Components & Logic
â”‚   â””â”€â”€ package.json        # Frontend Dependencies
â”œâ”€â”€ requirements.txt        # Python Dependencies
â”œâ”€â”€ uv.lock                 # UV Lockfile
â””â”€â”€ README.md               # You are here!
```

---

## ğŸ‘¥ Contributing

1. **Check Dependencies:** Always use `uv sync` after pulling changes.
2. **Coding Standards:** Follow PEP8 for Python and Prettier for JS/TS.
3. **Environment:** Keep your `.env` file updated but never commit it to Git.

---

## â“ Troubleshooting

- **Redis Connection Error:** Ensure the Docker container is running (`docker ps`).
- **ModuleNotFoundError:** Run `uv sync` again to ensure the virtual environment is up to date.
- **CORS Issues:** The backend is configured to allow all origins by default in development.

---
